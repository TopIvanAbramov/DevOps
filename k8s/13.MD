### **K8 stateful set**

```
kubectl get po,sts,svc,pvc
```

```
NAME              READY   STATUS    RESTARTS   AGE
pod/flask-app-0   1/1     Running   0          10m23s
pod/flask-app-1   1/1     Running   0          10m20s
pod/flask-app-2   1/1     Running   0          9m49s

NAME                         READY   AGE
statefulset.apps/flask-app   3/3     10m23s

NAME                TYPE           CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE
service/flask-app   LoadBalancer   10.107.40.67   127.0.0.1     8000:31814/TCP   10m23s
service/kubernetes  ClusterIP      10.96.0.1      <none>        443/TCP          15d

NAME                                STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
persistentvolumeclaim/flask-app-0   Bound    pvc-7b7461d5-d423-431d-a651-d44882dbe1bd   256M       RWO            standard       33m
persistentvolumeclaim/flask-app-1   Bound    pvc-4dc38a46-54d2-5c74-aa75-1048636ef04e   256M       RWO            standard       33m
persistentvolumeclaim/flask-app-2   Bound    pvc-53b6d1ds-a4cf-541e-996e-e8b14699fc14   256M       RWO            standard       33m
```

**Use several tabs in browser, incognito mode, etc to access the root path of app. And Check the content of your file, in each pod:**

```
kubectl exec pod/flask-app-0 --tail -n 5 /tmp/tmp.csv 
```
```
2021-10-03T14:48:12.885529+03:00
2021-10-03T14:48:25.886106+03:00
2021-10-03T14:48:25.886447+03:00
2021-10-03T14:48:33.851373+03:00
2021-10-03T14:48:34.861626+03:00
```

**Compare with output of:**
```
kubectl exec pod/flask-app-1 --tail -n 5 /tmp/tmp.csv 
```

```
2021-10-03T14:48:12.943035+03:00
2021-10-03T14:48:25.942856+03:00
2021-10-03T14:48:25.943048+03:00
2021-10-03T14:48:33.907668+03:00
2021-10-03T14:48:34.909238+03:00
```

**Describe and explain in the report the differences between the output of the command for replicas:**

> Deployment lead to creation of single PersistentVolumeClaim for each pods. Because of that race conditions occurred: all instances write to same file. But stateful state uses  volumeClaimTemplates (template for every pod) and all instance work with different files (No race condition).

**For our app ordering guarantee are unnecessary. Describe in the report why:**

> Sometimes we need a strict order of pods, because some of them may depend on others. But in our case we can turn it off, because there is no dependencies. This will speedup roollbacks as well as deployments.

**Then find a way to tell to the StatefulSet controller to launch or terminate all Pods in parallel:**

> There exists two stateful policies:
> 1) Parallel 
> 2) Ordered
> 
> So we can simply use parallel policy:

```
helm secrets install app-python ./flask-app -f ./flask-app/secrets.yaml > /dev/null
```
```
kubectl get po
```

```
 NAME          READY   STATUS        RESTARTS   AGE
 flask-app-0   1/1     Terminating   0          34m
 flask-app-1   1/1     Terminating   0          33m
 flask-app-2   1/1     Terminating   0          33m
```

Output of:
```
kubectl get po
```

```
 No resources found in default namespace.
```

Output of:
```
kubectl get po
```

```
 NAME          READY   STATUS    RESTARTS   AGE
 flask-app-0   0/1     Running   0          6s
 flask-app-1   0/1     Running   0          6s
 flask-app-2   0/1     Running   0          6s
```